{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0043f214-cba6-481c-b1da-318efcada5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/benhamner/nips-papers?select=papers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402430fa-0353-4597-a5bb-ee536b705edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526b9962-0ed1-46da-8f3e-eace961c1e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading english: Package 'english' not found in\n",
      "[nltk_data]     index\n"
     ]
    }
   ],
   "source": [
    "nltk.download('english')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d219f565-382f-45ec-ae1a-b67d390bebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9daa218-ef65-46ef-a97f-c2faa629ab3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d153179-c057-4968-8007-dcbfef4725d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1530</td>\n",
       "      <td>1998</td>\n",
       "      <td>A Precise Characterization of the Class of Lan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1530-a-precise-characterization-of-the-class-o...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>A Precise Characterization of the Class of\\nLa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>466</td>\n",
       "      <td>1991</td>\n",
       "      <td>A Contrast Sensitive Silicon Retina with Recip...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>466-a-contrast-sensitive-silicon-retina-with-r...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>A Contrast Sensitive Silicon Retina with\\nReci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1008</td>\n",
       "      <td>1994</td>\n",
       "      <td>Multidimensional Scaling and Data Clustering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008-multidimensional-scaling-and-data-cluster...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Multidimensional Scaling and Data Clustering\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>3954</td>\n",
       "      <td>2010</td>\n",
       "      <td>Learning Kernels with Radiuses of Minimum Encl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3954-learning-kernels-with-radiuses-of-minimum...</td>\n",
       "      <td>In this paper, we point out that there exist s...</td>\n",
       "      <td>Learning Kernels with Radiuses of Minimum\\nEnc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>3214</td>\n",
       "      <td>2007</td>\n",
       "      <td>Markov Chain Monte Carlo with People</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3214-markov-chain-monte-carlo-with-people.pdf</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Markov Chain Monte Carlo with People\\n\\nAdam N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  year                                              title  \\\n",
       "580   1530  1998  A Precise Characterization of the Class of Lan...   \n",
       "4043   466  1991  A Contrast Sensitive Silicon Retina with Recip...   \n",
       "11    1008  1994       Multidimensional Scaling and Data Clustering   \n",
       "3261  3954  2010  Learning Kernels with Radiuses of Minimum Encl...   \n",
       "2441  3214  2007               Markov Chain Monte Carlo with People   \n",
       "\n",
       "     event_type                                           pdf_name  \\\n",
       "580         NaN  1530-a-precise-characterization-of-the-class-o...   \n",
       "4043        NaN  466-a-contrast-sensitive-silicon-retina-with-r...   \n",
       "11          NaN  1008-multidimensional-scaling-and-data-cluster...   \n",
       "3261        NaN  3954-learning-kernels-with-radiuses-of-minimum...   \n",
       "2441        NaN      3214-markov-chain-monte-carlo-with-people.pdf   \n",
       "\n",
       "                                               abstract  \\\n",
       "580                                    Abstract Missing   \n",
       "4043                                   Abstract Missing   \n",
       "11                                     Abstract Missing   \n",
       "3261  In this paper, we point out that there exist s...   \n",
       "2441                                   Abstract Missing   \n",
       "\n",
       "                                             paper_text  \n",
       "580   A Precise Characterization of the Class of\\nLa...  \n",
       "4043  A Contrast Sensitive Silicon Retina with\\nReci...  \n",
       "11    Multidimensional Scaling and Data Clustering\\n...  \n",
       "3261  Learning Kernels with Radiuses of Minimum\\nEnc...  \n",
       "2441  Markov Chain Monte Carlo with People\\n\\nAdam N...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e18b66-06d1-4122-9f01-a3d4411231f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7241, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a458c5-c998-4308-9950-d7b8029c72fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "year             0\n",
       "title            0\n",
       "event_type    4819\n",
       "pdf_name         0\n",
       "abstract         0\n",
       "paper_text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a3a7d-0ca4-4af2-a573-c5881d5d72b9",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea84438-9546-4c26-a375-fe5d2f667539",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac8e3d3-e894-4cff-be66-b5e90cb9bac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfd34b1e-1652-45ea-b4bd-caf6b33f83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb4bc31-6629-4b1c-ae8e-3a425deb5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = ['fig', 'figure', 'image', 'sample', 'using', 'show', 'result', 'large', 'also', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "stop_words = list(stop_words.union(new_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea52f5b-87c8-4edb-ae05-1879d54e13c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['four',\n",
       " 'above',\n",
       " 'those',\n",
       " 'isn',\n",
       " 'an',\n",
       " \"isn't\",\n",
       " \"she's\",\n",
       " 'these',\n",
       " 'itself',\n",
       " 'ma',\n",
       " 'same',\n",
       " \"haven't\",\n",
       " \"should've\",\n",
       " 're',\n",
       " 'again',\n",
       " 'me',\n",
       " 'for',\n",
       " 'nine',\n",
       " 'most',\n",
       " 'about',\n",
       " 'before',\n",
       " 'this',\n",
       " 'against',\n",
       " 'we',\n",
       " 'just',\n",
       " 'sample',\n",
       " 'who',\n",
       " 'three',\n",
       " 'because',\n",
       " \"you're\",\n",
       " 'below',\n",
       " 'that',\n",
       " 'from',\n",
       " 'only',\n",
       " \"you'll\",\n",
       " 'whom',\n",
       " 'when',\n",
       " 's',\n",
       " 'large',\n",
       " 'her',\n",
       " 'as',\n",
       " 'he',\n",
       " 'using',\n",
       " 'image',\n",
       " 'theirs',\n",
       " 'mightn',\n",
       " 'it',\n",
       " \"aren't\",\n",
       " \"didn't\",\n",
       " 'so',\n",
       " \"mightn't\",\n",
       " 'off',\n",
       " 'were',\n",
       " 'yourselves',\n",
       " 'am',\n",
       " 'wouldn',\n",
       " 'should',\n",
       " 'under',\n",
       " 'will',\n",
       " \"that'll\",\n",
       " 'out',\n",
       " 'haven',\n",
       " 'until',\n",
       " 'hasn',\n",
       " \"needn't\",\n",
       " 'my',\n",
       " 'very',\n",
       " 'which',\n",
       " 'm',\n",
       " \"you'd\",\n",
       " 'further',\n",
       " 'the',\n",
       " 'mustn',\n",
       " 'to',\n",
       " 'them',\n",
       " 'into',\n",
       " 'can',\n",
       " 've',\n",
       " 'no',\n",
       " 'more',\n",
       " 'all',\n",
       " 'nor',\n",
       " 'she',\n",
       " 'six',\n",
       " 'their',\n",
       " 'll',\n",
       " 'do',\n",
       " 'weren',\n",
       " 'two',\n",
       " 'down',\n",
       " 't',\n",
       " 'five',\n",
       " 'other',\n",
       " 'they',\n",
       " \"weren't\",\n",
       " 'fig',\n",
       " 'now',\n",
       " 'result',\n",
       " \"mustn't\",\n",
       " 'his',\n",
       " 'its',\n",
       " 'aren',\n",
       " 'himself',\n",
       " 'once',\n",
       " 'than',\n",
       " \"wouldn't\",\n",
       " 'such',\n",
       " 'figure',\n",
       " \"doesn't\",\n",
       " 'had',\n",
       " 'both',\n",
       " 'own',\n",
       " \"shouldn't\",\n",
       " 'myself',\n",
       " 'did',\n",
       " 'themselves',\n",
       " 'ourselves',\n",
       " 'up',\n",
       " 'wasn',\n",
       " 'some',\n",
       " \"it's\",\n",
       " 'but',\n",
       " 'herself',\n",
       " 'how',\n",
       " 'on',\n",
       " 'then',\n",
       " 'where',\n",
       " 'has',\n",
       " 'any',\n",
       " 'have',\n",
       " \"don't\",\n",
       " 'y',\n",
       " 'eight',\n",
       " \"you've\",\n",
       " \"couldn't\",\n",
       " 'one',\n",
       " 'be',\n",
       " 'over',\n",
       " 'o',\n",
       " 'doesn',\n",
       " 'if',\n",
       " 'i',\n",
       " 'being',\n",
       " 'show',\n",
       " 'few',\n",
       " 'what',\n",
       " 'not',\n",
       " 'hers',\n",
       " 'our',\n",
       " 'needn',\n",
       " 'yourself',\n",
       " 'doing',\n",
       " \"wasn't\",\n",
       " 'after',\n",
       " 'are',\n",
       " 'in',\n",
       " \"hasn't\",\n",
       " 'here',\n",
       " 'a',\n",
       " \"won't\",\n",
       " 'won',\n",
       " 'at',\n",
       " 'by',\n",
       " 'ain',\n",
       " 'does',\n",
       " 'shan',\n",
       " 'your',\n",
       " 'didn',\n",
       " 'seven',\n",
       " 'why',\n",
       " 'ours',\n",
       " 'was',\n",
       " \"hadn't\",\n",
       " 'you',\n",
       " 'during',\n",
       " 'couldn',\n",
       " 'him',\n",
       " 'don',\n",
       " \"shan't\",\n",
       " 'and',\n",
       " 'while',\n",
       " 'd',\n",
       " 'each',\n",
       " 'is',\n",
       " 'been',\n",
       " 'of',\n",
       " 'also',\n",
       " 'or',\n",
       " 'with',\n",
       " 'between',\n",
       " 'through',\n",
       " 'having',\n",
       " 'yours',\n",
       " 'shouldn',\n",
       " 'too',\n",
       " 'hadn',\n",
       " 'there']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91e0452a-7d48-45dc-b0b5-cc33a8189da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>1945</td>\n",
       "      <td>2001</td>\n",
       "      <td>Natural Language Grammar Induction Using a Con...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1945-natural-language-grammar-induction-using-...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Natural Language Grammar Induction using a\\nCo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>253</td>\n",
       "      <td>1989</td>\n",
       "      <td>Subgrouping Reduces Complexity and Speeds Up L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>253-subgrouping-reduces-complexity-and-speeds-...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>638\\n\\nZipser\\n\\nSubgrouping Reduces Complexit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>4994</td>\n",
       "      <td>2013</td>\n",
       "      <td>Optimal Neural Population Codes for High-dimen...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>4994-optimal-neural-population-codes-for-high-...</td>\n",
       "      <td>How does neural population process sensory inf...</td>\n",
       "      <td>Fisher-Optimal Neural Population Codes for\\nHi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td>6756</td>\n",
       "      <td>2017</td>\n",
       "      <td>A Scale Free Algorithm for Stochastic Bandits ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>6756-a-scale-free-algorithm-for-stochastic-ban...</td>\n",
       "      <td>Existing strategies for finite-armed stochasti...</td>\n",
       "      <td>A Scale Free Algorithm for Stochastic Bandits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>3779</td>\n",
       "      <td>2009</td>\n",
       "      <td>Graph Zeta Function in the Bethe Free Energy a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3779-graph-zeta-function-in-the-bethe-free-ene...</td>\n",
       "      <td>We propose a new approach to the analysis of L...</td>\n",
       "      <td>Graph Zeta Function in the Bethe Free Energy a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  year                                              title  \\\n",
       "1034  1945  2001  Natural Language Grammar Induction Using a Con...   \n",
       "1683   253  1989  Subgrouping Reduces Complexity and Speeds Up L...   \n",
       "4412  4994  2013  Optimal Neural Population Codes for High-dimen...   \n",
       "6363  6756  2017  A Scale Free Algorithm for Stochastic Bandits ...   \n",
       "3066  3779  2009  Graph Zeta Function in the Bethe Free Energy a...   \n",
       "\n",
       "     event_type                                           pdf_name  \\\n",
       "1034        NaN  1945-natural-language-grammar-induction-using-...   \n",
       "1683        NaN  253-subgrouping-reduces-complexity-and-speeds-...   \n",
       "4412     Poster  4994-optimal-neural-population-codes-for-high-...   \n",
       "6363     Poster  6756-a-scale-free-algorithm-for-stochastic-ban...   \n",
       "3066        NaN  3779-graph-zeta-function-in-the-bethe-free-ene...   \n",
       "\n",
       "                                               abstract  \\\n",
       "1034                                   Abstract Missing   \n",
       "1683                                   Abstract Missing   \n",
       "4412  How does neural population process sensory inf...   \n",
       "6363  Existing strategies for finite-armed stochasti...   \n",
       "3066  We propose a new approach to the analysis of L...   \n",
       "\n",
       "                                             paper_text  \n",
       "1034  Natural Language Grammar Induction using a\\nCo...  \n",
       "1683  638\\n\\nZipser\\n\\nSubgrouping Reduces Complexit...  \n",
       "4412  Fisher-Optimal Neural Population Codes for\\nHi...  \n",
       "6363  A Scale Free Algorithm for Stochastic Bandits ...  \n",
       "3066  Graph Zeta Function in the Bethe Free Energy a...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90a4a37b-bd29-40f1-bad9-cd0f50c79fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing on text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff1b8fc3-793f-40a8-96dc-4bfb3de1791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d83b575-e648-4c85-bc65-9b7642f18783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    text = BeautifulSoup(text, 'html.parser')\n",
    "    text = text.get_text()\n",
    "    if not text.strip():\n",
    "        return 'empty_text'\n",
    "    text = nltk.word_tokenize(text)\n",
    "\n",
    "    text = [word for word in text if word not in stop_words and word not in punc]\n",
    "\n",
    "    text = [word for word in text if len(word) > 3]\n",
    "\n",
    "    text = [word for word in text]\n",
    "\n",
    "    text = [stemming.stem(word) for word in text]\n",
    "\n",
    "\n",
    "    return ' '.join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc3281d9-70d5-4c94-b4f1-2fc7afdaf543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1run runner run lover love love pyth meant repres punctuat mark want filter need includ proper condit check whether word punctuat mark correct'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing(\"\"\"1 1run 10 runner running lover loving love  This is PYth!.>n is meant to represent \n",
    "punctuation marks that you want to filter out, you need to\n",
    "include a proper condition to check whether\n",
    "the word is not\n",
    "a punctuation mark. Here's the correcte\n",
    "<html>\n",
    "</html>\n",
    "              \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff854242-02ff-4369-a201-1248958d91f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 7241/7241 [11:45<00:00, 10.26it/s]\n"
     ]
    }
   ],
   "source": [
    "docs = df['paper_text'].progress_apply(preprocessing)\n",
    "\n",
    "\n",
    "# n_jobs = 16  # Number of jobs (adjust based on your CPU cores)\n",
    "# processed_texts = Parallel(n_jobs=n_jobs)(\n",
    "#     delayed(preprocessing)(text) for text in tqdm(df['paper_text'], desc=\"Processing\")\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27309e1a-56c2-46b3-8bb3-08c79b816023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       self-organ associ databas applic hisashi suzuk...\n",
       "1       mean field theori layer visual cortex applic a...\n",
       "2       store covari associ long term potenti depress ...\n",
       "3       bayesian queri construct neural network model ...\n",
       "4       neural network ensembl cross valid activ learn...\n",
       "                              ...                        \n",
       "7236    singl transistor learn synaps paul hasler chri...\n",
       "7237    bia varianc combin least squar estim ronni mei...\n",
       "7238    real time cluster cmo neural engin serrano-got...\n",
       "7239    learn direct global motion class psychophysica...\n",
       "7240    correl interpol network real-tim express analy...\n",
       "Name: paper_text, Length: 7241, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8752674-417e-4f3a-80f9-f39cbda021ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_df=0.90, max_features=5000, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a31cb86f-2b19-474e-9932-93973ee0c1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7241/7241 [02:08<00:00, 56.23it/s]\n"
     ]
    }
   ],
   "source": [
    "word_count_vectors = cv.fit_transform(tqdm(df['paper_text'], desc=\"Vectorizing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d942f0af-f1ac-47d3-9317-b75b7a74edba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 2, ..., 2, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeee5f6a-625a-48c3-a127-02b8b52523a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7241, 5000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vectors.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04acca-5813-4a25-916d-9537ed601a37",
   "metadata": {},
   "source": [
    "### Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f24bb4d2-0d39-4e46-98a9-7d0e7bce3bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a294c32b-453c-4015-a8e7-3b85c4c21a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(smooth_idf=True, use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e941299-ec46-4811-8f41-fc1bf96c161e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_count_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1a8a201-0203-4f5b-946e-2634321e936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = tfidf.fit(word_count_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc5c1f7c-c282-4d50-957d-398b4100a971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.TfidfTransformer"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfidf_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1d8dc0e-081e-4ef5-8c81-02947312bfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.TfidfTransformer"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfidf_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a3b2b3-5752-430d-8296-03a8aeb03cff",
   "metadata": {},
   "source": [
    "### KeyWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d33bd7c-575e-4569-a496-0ae3283857ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>2376</td>\n",
       "      <td>2003</td>\n",
       "      <td>Iterative Scaled Trust-Region Learning in Kryl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2376-iterative-scaled-trust-region-learning-in...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Iterative scaled trust-region learning in\\nKry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5251</th>\n",
       "      <td>5754</td>\n",
       "      <td>2015</td>\n",
       "      <td>COEVOLVE: A Joint Point Process Model for Info...</td>\n",
       "      <td>Oral</td>\n",
       "      <td>5754-coevolve-a-joint-point-process-model-for-...</td>\n",
       "      <td>Information diffusion in online social network...</td>\n",
       "      <td>COEVOLVE: A Joint Point Process Model for\\nInf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  year                                              title  \\\n",
       "1513  2376  2003  Iterative Scaled Trust-Region Learning in Kryl...   \n",
       "5251  5754  2015  COEVOLVE: A Joint Point Process Model for Info...   \n",
       "\n",
       "     event_type                                           pdf_name  \\\n",
       "1513        NaN  2376-iterative-scaled-trust-region-learning-in...   \n",
       "5251       Oral  5754-coevolve-a-joint-point-process-model-for-...   \n",
       "\n",
       "                                               abstract  \\\n",
       "1513                                   Abstract Missing   \n",
       "5251  Information diffusion in online social network...   \n",
       "\n",
       "                                             paper_text  \n",
       "1513  Iterative scaled trust-region learning in\\nKry...  \n",
       "5251  COEVOLVE: A Joint Point Process Model for\\nInf...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f36d06e5-051d-4294-bd53-1b52c67b657d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '00 00', '000', ..., 'zk', 'zn', 'zt'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bbfea30-7b6a-477e-a517-5e380ee03877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1bf9f7a-bb97-4688-bd55-c4b2156062a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d12dd9d1-3476-47f7-9c8b-45c54734fb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '00 00', '000', ..., 'zk', 'zn', 'zt'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c80df7-2397-484b-8ffb-7a731a6910ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== [Title] ========\n",
      "Approximate inference in continuous time Gaussian-Jump processes\n",
      "\n",
      "======== [Abstract] ========\n",
      "We present a novel approach to inference in conditionally Gaussian continuous time stochastic processes, where the latent process is a Markovian jump process. We first consider the case of jump-diffusion processes, where the drift of a linear stochastic differential equation can jump at arbitrary time points. We derive partial differential equations for exact inference and present a very efficient mean field approximation. By introducing a novel lower bound on the free energy, we then generalise our approach to Gaussian processes with arbitrary covariance, such as the non-Markovian RBF covariance. We present results on both simulated and real data, showing that the approach is very accurate in capturing latent dynamics and can be useful in a number of real data modelling tasks.\n",
      "\n",
      "======== [KeyWords] ========\n",
      "process 0.618\n",
      "infer 0.304\n",
      "gaussian 0.224\n",
      "posterior 0.213\n",
      "gaussian process 0.211\n",
      "time 0.165\n",
      "model 0.157\n",
      "smooth 0.156\n",
      "backward 0.137\n",
      "system 0.135\n"
     ]
    }
   ],
   "source": [
    "def get_keywords(idx, docs, topN=10):\n",
    "    # getting words count and importance\n",
    "    docs_words_count = tfidf_transformer.transform(cv.transform([docs[idx]]))\n",
    "\n",
    "    # sorting sparse matrix\n",
    "    docs_words_count = docs_words_count.tocoo()\n",
    "    tuples = zip(docs_words_count.col, docs_words_count.data)\n",
    "    sorted_items = sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "    # getting top 10 keywords\n",
    "    sorted_items = sorted_items[:topN]\n",
    "\n",
    "\n",
    "    score_vals = []\n",
    "    features_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        score_vals.append(round(score, 3))\n",
    "        features_vals.append(feature_names[idx])\n",
    "\n",
    "\n",
    "    # final result\n",
    "    results = {}\n",
    "    for idx in range(len(features_vals)):\n",
    "        results[features_vals[idx]] = score_vals[idx]\n",
    "\n",
    "    return results\n",
    "    \n",
    "    \n",
    "\n",
    "def print_keywords(idx, keywords, df):\n",
    "    print(\"======== [Title] ========\")\n",
    "    print(df[\"title\"][idx])\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('======== [Abstract] ========')\n",
    "    print(df['abstract'][idx])\n",
    "\n",
    "    print()\n",
    "    \n",
    "    print('======== [KeyWords] ========')\n",
    "\n",
    "    for k in keywords:\n",
    "        print(k, keywords[k])\n",
    "\n",
    "idx = 3339\n",
    "keywords = get_keywords(idx, docs)\n",
    "print_keywords(idx, keywords, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96722c3e-3807-4a25-8c26-165687d5aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(cv, open('count_vectorizer.pkl', 'wb'))\n",
    "pickle.dump(tfidf_transformer, open('tfidf_transformer.pkl', 'wb'))\n",
    "pickle.dump(feature_names, open('feature_names.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf73e67-412d-49cb-a8db-ee6d9a0bb87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
